{"metadata":{"colab":{"provenance":[],"collapsed_sections":["T-zuZ_HHvlzp","jPvOVXigirek","VVkLo9sAgcJ1","M52wf9vG1tR4","KlHuTDBdDB7k"]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"21515216e2ec4b6096bc64aa41fdab61":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_817897c7337249578bfec55acc50ad92","IPY_MODEL_fe9ea3a6a6c2493caf98b7a8e19c8775","IPY_MODEL_bd25c781799d490ca43403f562246013"],"layout":"IPY_MODEL_a0f8631776d6446087b916376a651b11"}},"817897c7337249578bfec55acc50ad92":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_16a1e634ecec40fdbe1ed8a0d3409700","placeholder":"​","style":"IPY_MODEL_6bb409b7ba0b45aea799df62326df7b5","value":""}},"fe9ea3a6a6c2493caf98b7a8e19c8775":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cfaac0dcf9d04aa4b57c19d7dc3987b1","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0af494495e6b4e6593ddf03b06732d45","value":1}},"bd25c781799d490ca43403f562246013":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_00b60c8138824ca4977568eee2fd7c2e","placeholder":"​","style":"IPY_MODEL_8997eb85206c4c289d205a1e4073147d","value":" 268/? [04:34&lt;00:00,  1.32it/s]"}},"a0f8631776d6446087b916376a651b11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16a1e634ecec40fdbe1ed8a0d3409700":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6bb409b7ba0b45aea799df62326df7b5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cfaac0dcf9d04aa4b57c19d7dc3987b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"0af494495e6b4e6593ddf03b06732d45":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"00b60c8138824ca4977568eee2fd7c2e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8997eb85206c4c289d205a1e4073147d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b9fe907cbdcf4f77a44599ffdefbef83":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_43e292da3dc446ffb80a795078fcf843","IPY_MODEL_610e0007ca7244c1a8bd02f53d87c189","IPY_MODEL_25dc018a04964291842568abf121f860"],"layout":"IPY_MODEL_35e1be5bc8c44305a768f9a63bd77e69"}},"43e292da3dc446ffb80a795078fcf843":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2337ba553d6149018cbcc57332febe48","placeholder":"​","style":"IPY_MODEL_b94a21d514b24ea199d2b4feef2c10e5","value":"100%"}},"610e0007ca7244c1a8bd02f53d87c189":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_31225c3dde2049418490f741bf75cdb2","max":30,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2c44d8f07c274c46936ec3e60aa5aa68","value":30}},"25dc018a04964291842568abf121f860":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3966621b34ca461badda52e2c2402fba","placeholder":"​","style":"IPY_MODEL_1d51fd42733d4d858c7a067b949fc2e6","value":" 30/30 [00:09&lt;00:00,  3.28it/s]"}},"35e1be5bc8c44305a768f9a63bd77e69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2337ba553d6149018cbcc57332febe48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b94a21d514b24ea199d2b4feef2c10e5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"31225c3dde2049418490f741bf75cdb2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c44d8f07c274c46936ec3e60aa5aa68":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3966621b34ca461badda52e2c2402fba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d51fd42733d4d858c7a067b949fc2e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"90a745a56b704f14a733c8817581a489":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8f074195d96c4bb491fb83a9e382e1ad","IPY_MODEL_de55a9057bee4c26bf19617c60bfe20d","IPY_MODEL_eacf97f304ff4ce2bfae4b3a1c4cae91"],"layout":"IPY_MODEL_f108cfa4904d4dc0a86b8e53d61b1f4d"}},"8f074195d96c4bb491fb83a9e382e1ad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_26187b2656474b4b9564ef3d0100fa64","placeholder":"​","style":"IPY_MODEL_b2badfde1d7945f69717c6fc868c5307","value":""}},"de55a9057bee4c26bf19617c60bfe20d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eedd575554ab421ab7a13eeeedff2c91","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fe5de501cec946399a02965ce701dba9","value":1}},"eacf97f304ff4ce2bfae4b3a1c4cae91":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_caceb649f2a64bbcac3aaddea6e2d7d8","placeholder":"​","style":"IPY_MODEL_1d00a96c45c24cfc98a707d970c30574","value":" 268/? [04:31&lt;00:00,  1.32it/s]"}},"f108cfa4904d4dc0a86b8e53d61b1f4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26187b2656474b4b9564ef3d0100fa64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2badfde1d7945f69717c6fc868c5307":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eedd575554ab421ab7a13eeeedff2c91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"fe5de501cec946399a02965ce701dba9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"caceb649f2a64bbcac3aaddea6e2d7d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d00a96c45c24cfc98a707d970c30574":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3a861f7a4936453ba894616ca2b692c9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_458dd75f364c4b86a3ec0bf3095543de","IPY_MODEL_0e8bfa0978e244b4af9ad79312d93574","IPY_MODEL_a63856b415024dff90c8fdd34fb17bb3"],"layout":"IPY_MODEL_aad4cc4c8fbb4de3964730273ef2c035"}},"458dd75f364c4b86a3ec0bf3095543de":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8c83867902549439a7e1ffd96289f2e","placeholder":"​","style":"IPY_MODEL_3f96643adc374e0ebaee79ea619e5bfe","value":"100%"}},"0e8bfa0978e244b4af9ad79312d93574":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b2c1fd8a3ce24cdaa0db8e9548bc26e4","max":30,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e1410e036b0444ecaeef82162746beb8","value":30}},"a63856b415024dff90c8fdd34fb17bb3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c7190de7a95c411d930c4571d679e0df","placeholder":"​","style":"IPY_MODEL_74369c6949da4a53b81d5d2a4002ad8d","value":" 30/30 [00:09&lt;00:00,  3.30it/s]"}},"aad4cc4c8fbb4de3964730273ef2c035":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8c83867902549439a7e1ffd96289f2e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f96643adc374e0ebaee79ea619e5bfe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b2c1fd8a3ce24cdaa0db8e9548bc26e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1410e036b0444ecaeef82162746beb8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c7190de7a95c411d930c4571d679e0df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74369c6949da4a53b81d5d2a4002ad8d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3481c8f496334ffcaa4993ce2be51f36":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4de225a3bc6e460fa4dff167c1553eb9","IPY_MODEL_e4764e802630452799633df16ec8d89e","IPY_MODEL_35e2c81994ae4feb8c47f4c925ee2326"],"layout":"IPY_MODEL_a2cd88fd084845deab80936a2b7e1a72"}},"4de225a3bc6e460fa4dff167c1553eb9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c36a929b14c4488b004c1323f88dadf","placeholder":"​","style":"IPY_MODEL_03c177cffbeb4d01838879944e8a47c4","value":""}},"e4764e802630452799633df16ec8d89e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4088a1461a464b98a66952fd8968dd97","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_13e5435c05ac41db9639a3f50a05322b","value":1}},"35e2c81994ae4feb8c47f4c925ee2326":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d11b39b33114bcca9b9caf7b20ad0f2","placeholder":"​","style":"IPY_MODEL_994bc10221ed48b58a631a38f3b45411","value":" 268/? [04:31&lt;00:00,  1.32it/s]"}},"a2cd88fd084845deab80936a2b7e1a72":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c36a929b14c4488b004c1323f88dadf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03c177cffbeb4d01838879944e8a47c4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4088a1461a464b98a66952fd8968dd97":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"13e5435c05ac41db9639a3f50a05322b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5d11b39b33114bcca9b9caf7b20ad0f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"994bc10221ed48b58a631a38f3b45411":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c88cf891881c4e04903c61cbadeb24bf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1b2ef6f167f946618098347a5d81d59c","IPY_MODEL_1b1803be329443818921e20e3d047df4","IPY_MODEL_8aa81f9928504513a6448c36345432a7"],"layout":"IPY_MODEL_f444e6f0b4c74bf0ac130052f14db751"}},"1b2ef6f167f946618098347a5d81d59c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_074972dcec784abaa8fdeedeb00cb946","placeholder":"​","style":"IPY_MODEL_e3b3c24b99e34c7ea23d9ddad6213b11","value":"100%"}},"1b1803be329443818921e20e3d047df4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4efdb75f89724227bf08dc18ff11cd56","max":30,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7e07c6fb8d3b48ffb6ad87915059de0f","value":30}},"8aa81f9928504513a6448c36345432a7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b6e1f4769f724ce2955ea01033d41032","placeholder":"​","style":"IPY_MODEL_e3de6b7210b6488daf0cfb3cba36bf55","value":" 30/30 [00:09&lt;00:00,  3.27it/s]"}},"f444e6f0b4c74bf0ac130052f14db751":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"074972dcec784abaa8fdeedeb00cb946":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3b3c24b99e34c7ea23d9ddad6213b11":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4efdb75f89724227bf08dc18ff11cd56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e07c6fb8d3b48ffb6ad87915059de0f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b6e1f4769f724ce2955ea01033d41032":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3de6b7210b6488daf0cfb3cba36bf55":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"521447752fe04897ba631cdc4006c0d2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_67c7e585b5de402b88fa17c75ba651df","IPY_MODEL_3eba81130ddc44e9b595fc6f03556b3b","IPY_MODEL_d6f2769cd982457898f8c886dc08afda"],"layout":"IPY_MODEL_2139895107464e8eb31ee8581047d46a"}},"67c7e585b5de402b88fa17c75ba651df":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_afe4757bdd254a4abea42a7fdd9307fa","placeholder":"​","style":"IPY_MODEL_3c72ccdce0334bdcbb8f14ffeebcc683","value":""}},"3eba81130ddc44e9b595fc6f03556b3b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_171bb22c6230422e91e6ed01e13a07f2","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6cb0516944794aa29ae320c4b4e8e641","value":1}},"d6f2769cd982457898f8c886dc08afda":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_35d3057a50664d86a7fb06e309ae75c0","placeholder":"​","style":"IPY_MODEL_9ff308f29dce490c8f2e17f3b87d594f","value":" 268/? [04:31&lt;00:00,  1.33it/s]"}},"2139895107464e8eb31ee8581047d46a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"afe4757bdd254a4abea42a7fdd9307fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c72ccdce0334bdcbb8f14ffeebcc683":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"171bb22c6230422e91e6ed01e13a07f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"6cb0516944794aa29ae320c4b4e8e641":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"35d3057a50664d86a7fb06e309ae75c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ff308f29dce490c8f2e17f3b87d594f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c82af7df27a8413bb6afc779f94138a6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3136e18069d842ca81b9b1215dfa80c4","IPY_MODEL_4f2ef901ef8742268a4ac1b0cbf14c21","IPY_MODEL_f55fde6c92ac473f9f5bc56e376bda8a"],"layout":"IPY_MODEL_ee6242db9df043bcacfc553d35581f93"}},"3136e18069d842ca81b9b1215dfa80c4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f84e95eefac465f8ca0e67d919c6bca","placeholder":"​","style":"IPY_MODEL_b7a8760b66dc4a70883730d9df0dc6be","value":"100%"}},"4f2ef901ef8742268a4ac1b0cbf14c21":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc3f177cbec34d60a7b10e38a85b5fcc","max":30,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f11bd3811de5458ca88c0a176a71707e","value":30}},"f55fde6c92ac473f9f5bc56e376bda8a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_84a5fe7d6fe1460e8e4d101774fbfb23","placeholder":"​","style":"IPY_MODEL_b6f5f587ae0e4191856a4e172676149a","value":" 30/30 [00:09&lt;00:00,  3.30it/s]"}},"ee6242db9df043bcacfc553d35581f93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f84e95eefac465f8ca0e67d919c6bca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7a8760b66dc4a70883730d9df0dc6be":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bc3f177cbec34d60a7b10e38a85b5fcc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f11bd3811de5458ca88c0a176a71707e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"84a5fe7d6fe1460e8e4d101774fbfb23":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6f5f587ae0e4191856a4e172676149a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a7dcc5ab48da404aab9a4618aa367ebd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d27fce0e5b544b7fa1aa34a05527304b","IPY_MODEL_68b2ec06780d47618eb448e0ed2cd38a","IPY_MODEL_83eabf101e3e4d81a6c130d7b1d5bbcf"],"layout":"IPY_MODEL_32007ecdff85456e9f5d4e98bd0231b7"}},"d27fce0e5b544b7fa1aa34a05527304b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3f8451150394c08b385229a89240469","placeholder":"​","style":"IPY_MODEL_112d78d72c5b4aaea5052e128d740f3c","value":""}},"68b2ec06780d47618eb448e0ed2cd38a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_01914c2f39f54bada93cd227f13ca0bd","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_08719c6aaee8419e909b55b9d2f95ce4","value":1}},"83eabf101e3e4d81a6c130d7b1d5bbcf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc080d8209be460ea76146a72864c4c7","placeholder":"​","style":"IPY_MODEL_4e6aaf54b8594fed8e5fae34d9d6da14","value":" 268/? [04:30&lt;00:00,  1.32it/s]"}},"32007ecdff85456e9f5d4e98bd0231b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3f8451150394c08b385229a89240469":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"112d78d72c5b4aaea5052e128d740f3c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"01914c2f39f54bada93cd227f13ca0bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"08719c6aaee8419e909b55b9d2f95ce4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fc080d8209be460ea76146a72864c4c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e6aaf54b8594fed8e5fae34d9d6da14":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"337aaca14e45479aac3e36b8da21d1cd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0bb0aa87ffa54f88bc577b7fe2c62461","IPY_MODEL_0f793ec10f5a430c846a77c383d7d7a8","IPY_MODEL_bd698f5211c049439844a02d20980647"],"layout":"IPY_MODEL_1792340ec61e496b9480ffd78fa684e8"}},"0bb0aa87ffa54f88bc577b7fe2c62461":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d8a109af782470797f72310cf5f525e","placeholder":"​","style":"IPY_MODEL_8b992b08d1be4f369858aa7617361f0c","value":"100%"}},"0f793ec10f5a430c846a77c383d7d7a8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_168c146673ac49b1bb516aca8619723c","max":30,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1be8d961263d4155b2a0efdfa6504ac4","value":30}},"bd698f5211c049439844a02d20980647":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_43480c43ea68440ba4be5b67516452f2","placeholder":"​","style":"IPY_MODEL_d76b60be0c514f6db3f42bb584775732","value":" 30/30 [00:09&lt;00:00,  3.30it/s]"}},"1792340ec61e496b9480ffd78fa684e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d8a109af782470797f72310cf5f525e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b992b08d1be4f369858aa7617361f0c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"168c146673ac49b1bb516aca8619723c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1be8d961263d4155b2a0efdfa6504ac4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"43480c43ea68440ba4be5b67516452f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d76b60be0c514f6db3f42bb584775732":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"855dbb258664480680847c63be4d90fa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9fbeba74103b48249d3b785ffa62e6a7","IPY_MODEL_f864711c16524432a3734cb5d58f2407","IPY_MODEL_5ce0ed74a4e0499a85421bcd7690b38f"],"layout":"IPY_MODEL_401008ba84ea4a4b82833fad15f02822"}},"9fbeba74103b48249d3b785ffa62e6a7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_efab510782724a6196d3a3394207b280","placeholder":"​","style":"IPY_MODEL_5846ebeed02d4a4999600e49d6897e0d","value":"100%"}},"f864711c16524432a3734cb5d58f2407":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1abce60585684c568bad4b4909bfd31a","max":160,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4e2de13aaa824de8869d9e905ed8da12","value":160}},"5ce0ed74a4e0499a85421bcd7690b38f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8d5383819a14783850e8cd23c59791e","placeholder":"​","style":"IPY_MODEL_1cc6ef9bcd5c4d49b47978609f13a4f0","value":" 160/160 [00:56&lt;00:00,  3.43it/s]"}},"401008ba84ea4a4b82833fad15f02822":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efab510782724a6196d3a3394207b280":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5846ebeed02d4a4999600e49d6897e0d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1abce60585684c568bad4b4909bfd31a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e2de13aaa824de8869d9e905ed8da12":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e8d5383819a14783850e8cd23c59791e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1cc6ef9bcd5c4d49b47978609f13a4f0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Settings and Installing","metadata":{"id":"T-zuZ_HHvlzp"}},{"cell_type":"code","source":"!pip install transformers\n!pip install fastBPE\n!pip install fairseq\n!pip install emoji==1.7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"203FC6Hwu7kS","outputId":"6190eeaf-93a2-4301-87c3-bb40e80ffc19","execution":{"iopub.status.busy":"2022-12-15T11:01:33.411558Z","iopub.execute_input":"2022-12-15T11:01:33.411987Z","iopub.status.idle":"2022-12-15T11:02:34.389475Z","shell.execute_reply.started":"2022-12-15T11:01:33.411898Z","shell.execute_reply":"2022-12-15T11:02:34.388278Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.20.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.13.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.7.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.8.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.9.24)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.3)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.12)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting fastBPE\n  Downloading fastBPE-0.1.0.tar.gz (35 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: fastBPE\n  Building wheel for fastBPE (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for fastBPE: filename=fastBPE-0.1.0-cp37-cp37m-linux_x86_64.whl size=746409 sha256=b1f3d7acec52ee62ecc259771ca84dba772051139cc43ba8230b9a4ed3343da6\n  Stored in directory: /root/.cache/pip/wheels/bd/d4/0e/0d317a65f77d3f8049fedd8a2ee0519164cf3e6bd77ef886f1\nSuccessfully built fastBPE\nInstalling collected packages: fastBPE\nSuccessfully installed fastBPE-0.1.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting fairseq\n  Downloading fairseq-0.12.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n\u001b[?25hCollecting omegaconf<2.1\n  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\nRequirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (from fairseq) (2021.11.10)\nRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from fairseq) (1.11.0)\nRequirement already satisfied: cython in /opt/conda/lib/python3.7/site-packages (from fairseq) (0.29.32)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from fairseq) (4.64.0)\nRequirement already satisfied: cffi in /opt/conda/lib/python3.7/site-packages (from fairseq) (1.15.0)\nCollecting hydra-core<1.1,>=1.0.7\n  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from fairseq) (1.21.6)\nCollecting sacrebleu>=1.4.12\n  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: torchaudio>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from fairseq) (0.11.0)\nCollecting bitarray\n  Downloading bitarray-2.6.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (235 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.4/235.4 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting antlr4-python3-runtime==4.8\n  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: importlib-resources in /opt/conda/lib/python3.7/site-packages (from hydra-core<1.1,>=1.0.7->fairseq) (5.8.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from omegaconf<2.1->fairseq) (4.1.1)\nRequirement already satisfied: PyYAML>=5.1.* in /opt/conda/lib/python3.7/site-packages (from omegaconf<2.1->fairseq) (6.0)\nRequirement already satisfied: portalocker in /opt/conda/lib/python3.7/site-packages (from sacrebleu>=1.4.12->fairseq) (2.6.0)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.7/site-packages (from sacrebleu>=1.4.12->fairseq) (0.9.0)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.7/site-packages (from sacrebleu>=1.4.12->fairseq) (4.9.1)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.7/site-packages (from sacrebleu>=1.4.12->fairseq) (0.4.5)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi->fairseq) (2.21)\nRequirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.7/site-packages (from importlib-resources->hydra-core<1.1,>=1.0.7->fairseq) (3.8.0)\nBuilding wheels for collected packages: antlr4-python3-runtime\n  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=6f97d6f94c29e8e765122824afeae13c36d23a4db1b025e0e9dd8d785ed46b7b\n  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\nSuccessfully built antlr4-python3-runtime\nInstalling collected packages: bitarray, antlr4-python3-runtime, sacrebleu, omegaconf, hydra-core, fairseq\nSuccessfully installed antlr4-python3-runtime-4.8 bitarray-2.6.0 fairseq-0.12.2 hydra-core-1.0.7 omegaconf-2.0.6 sacrebleu-2.3.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting emoji==1.7\n  Downloading emoji-1.7.0.tar.gz (175 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.4/175.4 kB\u001b[0m \u001b[31m409.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: emoji\n  Building wheel for emoji (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171046 sha256=53bf419c9469046032657a4df03da99ab18cf43ed634074eb38e23dd68b8d5d9\n  Stored in directory: /root/.cache/pip/wheels/8a/4e/b6/57b01db010d17ef6ea9b40300af725ef3e210cb1acfb7ac8b6\nSuccessfully built emoji\nInstalling collected packages: emoji\n  Attempting uninstall: emoji\n    Found existing installation: emoji 2.1.0\n    Uninstalling emoji-2.1.0:\n      Successfully uninstalled emoji-2.1.0\nSuccessfully installed emoji-1.7.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install vncorenlp\n\n!mkdir -p vncorenlp/models/wordsegmenter\n!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar\n!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab\n!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr\n!mv VnCoreNLP-1.1.1.jar vncorenlp/ \n!mv vi-vocab vncorenlp/models/wordsegmenter/\n!mv wordsegmenter.rdr vncorenlp/models/wordsegmenter/!","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rwJNTm7DvY_Q","outputId":"36de0387-7a94-4072-984a-8d20b1593e54","execution":{"iopub.status.busy":"2022-12-15T11:02:34.392431Z","iopub.execute_input":"2022-12-15T11:02:34.392898Z","iopub.status.idle":"2022-12-15T11:02:58.187480Z","shell.execute_reply.started":"2022-12-15T11:02:34.392840Z","shell.execute_reply":"2022-12-15T11:02:58.186150Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting vncorenlp\n  Downloading vncorenlp-1.0.3.tar.gz (2.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from vncorenlp) (2.28.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->vncorenlp) (2022.9.24)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->vncorenlp) (3.3)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->vncorenlp) (1.26.12)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->vncorenlp) (2.1.0)\nBuilding wheels for collected packages: vncorenlp\n  Building wheel for vncorenlp (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for vncorenlp: filename=vncorenlp-1.0.3-py3-none-any.whl size=2645951 sha256=680031bdac1a21cece1622cc274704b208ebef8315b76e17c529585a9de6848c\n  Stored in directory: /root/.cache/pip/wheels/0c/d8/f2/d28d97379b4f6479bf51247c8dfd57fa00932fa7a74b6aab29\nSuccessfully built vncorenlp\nInstalling collected packages: vncorenlp\nSuccessfully installed vncorenlp-1.0.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m--2022-12-15 11:02:49--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 27412575 (26M) [application/octet-stream]\nSaving to: ‘VnCoreNLP-1.1.1.jar’\n\nVnCoreNLP-1.1.1.jar 100%[===================>]  26.14M   109MB/s    in 0.2s    \n\n2022-12-15 11:02:51 (109 MB/s) - ‘VnCoreNLP-1.1.1.jar’ saved [27412575/27412575]\n\n--2022-12-15 11:02:53--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 526544 (514K) [application/octet-stream]\nSaving to: ‘vi-vocab’\n\nvi-vocab            100%[===================>] 514.20K  --.-KB/s    in 0.05s   \n\n2022-12-15 11:02:53 (9.89 MB/s) - ‘vi-vocab’ saved [526544/526544]\n\n--2022-12-15 11:02:54--  https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 128508 (125K) [text/plain]\nSaving to: ‘wordsegmenter.rdr’\n\nwordsegmenter.rdr   100%[===================>] 125.50K  --.-KB/s    in 0.03s   \n\n2022-12-15 11:02:55 (4.62 MB/s) - ‘wordsegmenter.rdr’ saved [128508/128508]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"!wget https://public.vinai.io/PhoBERT_base_transformers.tar.gz\n!tar -xzvf PhoBERT_base_transformers.tar.gz","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MZWTSztYBFIy","outputId":"cb73d06b-fb31-40db-e174-b404da00d88f","execution":{"iopub.status.busy":"2022-12-15T11:02:58.189949Z","iopub.execute_input":"2022-12-15T11:02:58.192185Z","iopub.status.idle":"2022-12-15T11:03:27.457827Z","shell.execute_reply.started":"2022-12-15T11:02:58.192142Z","shell.execute_reply":"2022-12-15T11:03:27.456665Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"--2022-12-15 11:02:59--  https://public.vinai.io/PhoBERT_base_transformers.tar.gz\nResolving public.vinai.io (public.vinai.io)... 54.230.31.104, 54.230.31.76, 54.230.31.108, ...\nConnecting to public.vinai.io (public.vinai.io)|54.230.31.104|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 322405979 (307M) [application/x-tar]\nSaving to: ‘PhoBERT_base_transformers.tar.gz’\n\nPhoBERT_base_transf 100%[===================>] 307.47M  16.8MB/s    in 20s     \n\n2022-12-15 11:03:19 (15.4 MB/s) - ‘PhoBERT_base_transformers.tar.gz’ saved [322405979/322405979]\n\nPhoBERT_base_transformers/\nPhoBERT_base_transformers/config.json\nPhoBERT_base_transformers/bpe.codes\nPhoBERT_base_transformers/model.bin\nPhoBERT_base_transformers/dict.txt\n","output_type":"stream"}]},{"cell_type":"code","source":"from fairseq.data.encoders.fastbpe import fastBPE\nfrom fairseq.data import Dictionary\nimport argparse\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--bpe-codes', \n    default=\"/kaggle/working/PhoBERT_base_transformers/bpe.codes\",\n    required=False,\n    type=str,\n    help='path to fastBPE BPE'\n)\nargs, unknown = parser.parse_known_args()\nbpe = fastBPE(args)\n\n# Load the dictionary\nvocab = Dictionary()\nvocab.add_from_file(\"/kaggle/working/PhoBERT_base_transformers/dict.txt\")","metadata":{"id":"YGhKBZzkBOdC","execution":{"iopub.status.busy":"2022-12-15T11:03:27.460017Z","iopub.execute_input":"2022-12-15T11:03:27.460398Z","iopub.status.idle":"2022-12-15T11:03:31.358686Z","shell.execute_reply.started":"2022-12-15T11:03:27.460356Z","shell.execute_reply":"2022-12-15T11:03:31.357634Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"Loading codes from /kaggle/working/PhoBERT_base_transformers/bpe.codes ...\nRead 64000 codes from the codes file.\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow\nimport pandas as pd\nimport numpy as np\nimport re\nimport regex","metadata":{"id":"x1jRkc93Jw3J","execution":{"iopub.status.busy":"2022-12-15T11:03:31.364965Z","iopub.execute_input":"2022-12-15T11:03:31.368091Z","iopub.status.idle":"2022-12-15T11:03:35.114462Z","shell.execute_reply.started":"2022-12-15T11:03:31.368051Z","shell.execute_reply":"2022-12-15T11:03:35.113477Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"!pip install underthesea\nimport underthesea\nfrom underthesea import word_tokenize","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d5Vo1ihxVnC0","outputId":"2451b19f-7713-41e9-82d6-e11b8e0d8489","execution":{"iopub.status.busy":"2022-12-15T11:03:35.116037Z","iopub.execute_input":"2022-12-15T11:03:35.116452Z","iopub.status.idle":"2022-12-15T11:03:50.354413Z","shell.execute_reply.started":"2022-12-15T11:03:35.116413Z","shell.execute_reply":"2022-12-15T11:03:50.353328Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Collecting underthesea\n  Downloading underthesea-1.4.0-py3-none-any.whl (11.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from underthesea) (4.64.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from underthesea) (3.7)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from underthesea) (6.0)\nRequirement already satisfied: Click>=6.0 in /opt/conda/lib/python3.7/site-packages (from underthesea) (8.0.4)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from underthesea) (1.0.1)\nCollecting underthesea-core==0.0.5a2\n  Downloading underthesea_core-0.0.5_alpha.2-cp37-cp37m-manylinux2010_x86_64.whl (591 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.7/591.7 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting python-crfsuite>=0.9.6\n  Downloading python_crfsuite-0.9.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (965 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 kB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from underthesea) (1.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from underthesea) (2.28.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from Click>=6.0->underthesea) (4.13.0)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.7/site-packages (from nltk->underthesea) (2021.11.10)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->underthesea) (1.26.12)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->underthesea) (2.1.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->underthesea) (2022.9.24)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->underthesea) (3.3)\nRequirement already satisfied: numpy>=1.14.6 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->underthesea) (1.21.6)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->underthesea) (3.1.0)\nRequirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->underthesea) (1.7.3)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->Click>=6.0->underthesea) (4.1.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->Click>=6.0->underthesea) (3.8.0)\nInstalling collected packages: underthesea-core, python-crfsuite, underthesea\nSuccessfully installed python-crfsuite-0.9.8 underthesea-1.4.0 underthesea-core-0.0.5a2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"# Import data","metadata":{"id":"tZUQCRRLJOe-"}},{"cell_type":"code","source":"train_path = \"/kaggle/input/newdatafoody/train-set.csv\"\ntest_path = \"/kaggle/input/newdatafoody/test-set.csv\"\npos_path = \"/kaggle/input/newdatafoody/pos.txt\"\nneg_path = \"/kaggle/input/newdatafoody/neg.txt\"\nnot_path = \"/kaggle/input/newdatafoody/not.txt\"\nintensifier_path = \"/kaggle/input/newdatafoody/intensifier.txt\"","metadata":{"id":"Y0YnmFxdJTLn","execution":{"iopub.status.busy":"2022-12-15T11:03:50.355842Z","iopub.execute_input":"2022-12-15T11:03:50.356257Z","iopub.status.idle":"2022-12-15T11:03:50.380768Z","shell.execute_reply.started":"2022-12-15T11:03:50.356209Z","shell.execute_reply":"2022-12-15T11:03:50.379405Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_text, train_label = [], []\ntest_id, test_text = [], []\n\npos_list = pd.read_table(pos_path)\nneg_list = pd.read_table(neg_path)\nnot_list = pd.read_table(not_path)\nintensifier_list = pd.read_table(intensifier_path)\npos_list = pos_list.values.tolist()\nneg_list = neg_list.values.tolist()\nnot_list = not_list.values.tolist()\nintensifier_list = intensifier_list.values.tolist()\n\nfor i in range(len(pos_list)):\n    pos_list[i] = pos_list[i][0]\n\nfor i in range(len(neg_list)):\n    neg_list[i] = neg_list[i][0]\n\nfor i in range(len(not_list)):\n    not_list[i] = not_list[i][0]\n\nfor i in range(len(intensifier_list)):\n    intensifier_list[i] = intensifier_list[i][0]\n\ndf = pd.read_csv(\n    train_path,\n    names=[\"#\", \"RevId\", \"UserId\", \"Comment\", \"image_urls\", \"Rating\"])\n\ndf= df[(df['Rating']=='1') | (df['Rating']=='0')].reset_index(drop=True)\n\ndf = df[['Comment', 'Rating']]\n\ntrain_text = df['Comment']\ntrain_labels = df['Rating']\n\nnew_data = []\n\n#Thêm mẫu bằng cách lấy trong từ điển Sentiment (nag/pos)\nfor index,row in enumerate(neg_list):\n    new_data.append([row,'0'])\nfor index,row in enumerate(pos_list):\n    new_data.append([row,'1'])\n    \nnew_data.append([\"thậm tệ\", '0'])\nnew_data.append([\"xuất sắc\", '1'])\n    \naug_df_text = pd.Series( (v[0] for v in new_data) )\naug_df_labels = pd.Series( (v[1] for v in new_data) )\n\ntrain_text = train_text.append(aug_df_text).reset_index(drop=True)\ntrain_labels = train_labels.append(aug_df_labels).reset_index(drop=True)\n    \nprint(train_text)\nprint(train_labels)","metadata":{"id":"GLNllFx8JcA0","execution":{"iopub.status.busy":"2022-12-15T11:03:50.382460Z","iopub.execute_input":"2022-12-15T11:03:50.383544Z","iopub.status.idle":"2022-12-15T11:03:50.651101Z","shell.execute_reply.started":"2022-12-15T11:03:50.383501Z","shell.execute_reply":"2022-12-15T11:03:50.649876Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"0       Xôi dẻo, đồ ăn đậm vị. Hộp xôi được lót lá trô...\n1       Gọi ship 1 xuất cari gà bánh naan và 3 miếng g...\n2       Thời tiết lạnh như này, cả nhà rủ nhau đến leg...\n3       Em có đọc review thấy mng bảo trà sữa nướng đề...\n4       Đồ ăn rất ngon, nhà hàng cũng rất đẹp, tất cả ...\n                              ...                        \n9479                                               uy tín\n9480                                            tin tưởng\n9481                                              lễ phép\n9482                                              thậm tệ\n9483                                             xuất sắc\nLength: 9484, dtype: object\n0       1\n1       0\n2       1\n3       0\n4       1\n       ..\n9479    1\n9480    1\n9481    1\n9482    0\n9483    1\nLength: 9484, dtype: object\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Text preprocessing","metadata":{"id":"cLRXkOBNKVbK","_kg_hide-input":false}},{"cell_type":"code","source":"from collections import defaultdict\nMAX_LEN = 250","metadata":{"id":"72GKQu42bKz2","execution":{"iopub.status.busy":"2022-12-15T11:03:50.652734Z","iopub.execute_input":"2022-12-15T11:03:50.653539Z","iopub.status.idle":"2022-12-15T11:03:50.659124Z","shell.execute_reply.started":"2022-12-15T11:03:50.653501Z","shell.execute_reply":"2022-12-15T11:03:50.657885Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def emojis_abbreviations(text):\n    replace_list = {\n        #Quy các icon về 2 loại emoji: Tích cực hoặc tiêu cực\n        \"👹\": \"tệ\", \"👻\": \"tốt\", \"💃\": \"tốt\",'🤙': ' tốt ', '👍': ' tốt ',\n        \"💄\": \"tốt\", \"💎\": \"tốt\", \"💩\": \"tốt\",\"😕\": \"tệ\", \"😱\": \"tệ\", \"😸\": \"tốt\",\n        \"😾\": \"tệ\", \"🚫\": \"tệ\",  \"🤬\": \"tệ\",\"🧚\": \"tốt\", \"🧡\": \"tốt\",'🐶':' tốt ',\n        '👎': ' tệ ', '😣': ' tệ ','✨': ' tốt ', '❣': ' tốt ','☀': ' tốt ',\n        '♥': ' tốt ', '🤩': ' tốt ', 'like': ' tốt ', '💌': ' tốt ',\n        '🤣': ' tốt ', '🖤': ' tốt ', '🤤': ' tốt ', ':(': ' tệ ', '😢': ' tệ ',\n        '❤': ' tốt ', '😍': ' tốt ', '😘': ' tốt ', '😪': ' tệ ', '😊': ' tốt ',\n        '?': ' ? ', '😁': ' tốt ', '💖': ' tốt ', '😟': ' tệ ', '😭': ' tệ ',\n        '💯': ' tốt ', '💗': ' tốt ', '♡': ' tốt ', '💜': ' tốt ', '🤗': ' tốt ',\n        '^^': ' tốt ', '😨': ' tệ ', '☺': ' tốt ', '💋': ' tốt ', '👌': ' tốt ',\n        '😖': ' tệ ', '😀': ' tốt ', ':((': ' tệ ', '😡': ' tệ ', '😠': ' tệ ',\n        '😒': ' tệ ', '🙂': ' tốt ', '😏': ' tệ ', '😝': ' tốt ', '😄': ' tốt ',\n        '😙': ' tốt ', '😤': ' tệ ', '😎': ' tốt ', '😆': ' tốt ', '💚': ' tốt ',\n        '✌': ' tốt ', '💕': ' tốt ', '😞': ' tệ ', '😓': ' tệ ', '️🆗️': ' tốt ',\n        '😉': ' tốt ', '😂': ' tốt ', ':v': '  tốt ', '=))': '  tốt ', '😋': ' tốt ',\n        '💓': ' tốt ', '😐': ' tệ ', ':3': ' tốt ', '😫': ' tệ ', '😥': ' tệ ',\n        '😃': ' tốt ', '😬': ' 😬 ', '😌': ' 😌 ', '💛': ' tốt ', '🤝': ' tốt ', '🎈': ' tốt ',\n        '😗': ' tốt ', '🤔': ' tệ ', '😑': ' tệ ', '🔥': ' tệ ', '🙏': ' tệ ',\n        '🆗': ' tốt ', '😻': ' tốt ', '💙': ' tốt ', '💟': ' tốt ',\n        '😚': ' tốt ', '❌': ' tệ ', '👏': ' tốt ', ';)': ' tốt ', '<3': ' tốt ',\n        '🌝': ' tốt ',  '🌷': ' tốt ', '🌸': ' tốt ', '🌺': ' tốt ',\n        '🌼': ' tốt ', '🍓': ' tốt ', '🐅': ' tốt ', '🐾': ' tốt ', '👉': ' tốt ',\n        '💐': ' tốt ', '💞': ' tốt ', '💥': ' tốt ', '💪': ' tốt ',\n        '💰': ' tốt ',  '😇': ' tốt ', '😛': ' tốt ', '😜': ' tốt ',\n        '🙃': ' tốt ', '🤑': ' tốt ', '🤪': ' tốt ','☹': ' tệ ',  '💀': ' tệ ',\n        '😔': ' tệ ', '😧': ' tệ ', '😩': ' tệ ', '😰': ' tệ ', '😳': ' tệ ',\n        '😵': ' tệ ', '😶': ' tệ ', '🙁': ' tệ ',\n        #Chuẩn hóa 1 số sentiment words/English words\n        ':))': '  tốt ', '=)': ' tốt ',':>': ' tốt ','<3': ' tốt ', ':3': ' tốt ', 'ô kêi': ' ok ', 'okie': ' ok ', ' o kê ': ' ok ',\n        'okey': ' ok ', 'ôkê': ' ok ', 'oki': ' ok ',' ô kê ': ' ok ', ' oke ':  ' ok ',' okay':' ok ','okê':' ok ',\n        ' tks ': u' cám ơn ', 'thks': u' cám ơn ', 'thanks': u' cám ơn ', 'ths': u' cám ơn ', 'thank': u' cám ơn ',\n        '⭐': 'star ', '*': 'star ', '🌟': 'star ', '🎉': u' tốt ',\n        'kg ': u' không ', ' mk ': u' mình ', ' mik ': u' mình ', ' thik ' : u' thích ', 'not': u' không ',' nma ': u' nhưng mà ', u' kg ': u' không ', '\"k ': u' không ',' kh ':u' không ','kô':u' không ','hok':u' không ',' kp ': u' không phải ',u' kô ': u' không ', '\"ko ': u' không ', u' ko ': u' không ', u' k ': u' không ', 'khong': u' không ', u' hok ': u' không ',\n        'he he': ' tốt ','hehe': ' tốt ','hihi': ' tốt ', 'haha': ' tốt ', 'hjhj': ' tốt ',\n        ' lol ': ' tệ ',' cc ': ' tệ ','cute': u' dễ thương ','huhu': ' tệ ', ' vs ': u' với ', 'wa': ' quá ', 'wá': u' quá', 'j': u' gì ', '“': ' ',\n        ' sz ': u' cỡ ', 'size': u' cỡ ', u' đx ': u' được ', 'dk': u' được ', 'dc': u' được ', 'đk': u' được ',\n        'đc': u' được ', ' qly ': u' quản lý ','authentic': u' chuẩn chính hãng ',u' aut ': u' chuẩn chính hãng ', u' auth ': u' chuẩn chính hãng ', 'thick': u' tốt ', 'store': u' cửa hàng ',\n        'shop': u' cửa hàng ', ' sp ': u' sản phẩm ',u' nv ': u' nhân viên ',' lớm ': u' lắm ', 'gud': u' tốt ','god': u' tốt ','wel done':' tốt ', 'good': u' tốt ', 'gút': u' tốt ',\n        'sấu': u' xấu ','gut': u' tốt ', u' tot ': u' tốt ', u' nice ': u' tốt ', 'perfect': 'rất tốt', 'bt': u' bình thường ',\n        'time': u' thời gian ', 'dễ tìm': 'dễ tìm tốt', 'qá': u' quá ', u' ship ': u' giao hàng ', u' m ': u' mình ', u' mik ': u' mình ',\n        'ể': 'ể', 'product': 'sản phẩm', 'quality': 'chất lượng','chat':' chất ', 'excelent': 'hoàn hảo', 'bad': 'tệ','fresh': ' tươi ','sad': ' tệ ',\n        ' date ': u' hạn sử dụng ', 'hsd': u' hạn sử dụng ','quickly': u' nhanh ', 'quick': u' nhanh ','fast': u' nhanh ','delivery': u' giao hàng ',u' síp ': u' giao hàng ',\n        ' beautiful ': u' đẹp tốt vời ', u' tl ': u' trả lời ', u' r ': u' rồi ', u' shopE ': u' cửa hàng ',\n        'chất lg': u' chất lượng ',u' sd ': u' sử dụng ',u' dt ': u' điện thoại ',u' nt ': u' nhắn tin ',u' tl ': u' trả lời ',u' sài ': u' xài ',u'bjo':u' bao giờ ',\n        'thik': u' thích ',u' sop ': u' cửa hàng ', ' fb ': ' facebook ', ' face ': ' facebook ', ' very ': u' rất ',u'quả ng ':u' quảng  ',\n        'dep': u' đẹp ',u' xau ': u' xấu ','delicious': u' ngon ', u'hàg': u' hàng ', u'qủa': u' quả ',\n        ' iu ': u' yêu ',' fake ': u' giả mạo ', 'trl': 'trả lời', ' >< ': u' tốt ',\n        ' por ': u' tệ ',' poor ': u' tệ ', ' ib ':u' nhắn tin ', 'rep':u' trả lời ',u'fback':' feedback ','fedback':' feedback ',\n        #dưới 3* quy về 1*, trên 3* quy về 5*\n        '6 sao': ' 5star ','6 star': ' 5star ', '5star': ' 5star ','5 sao': ' 5star ','5sao': ' 5star ',\n        'starstarstarstarstar': ' 5star ', '1 sao': ' 1star ', '1sao': ' 1star ','2 sao':' 1star ','2sao':' 1star ',\n        '2 starstar':' 1star ','1star': ' 1star ', '0 sao': ' 1star ', '0star': ' 1star ',}\n\n    for k, v in replace_list.items():\n        text = text.replace(k, v)\n\n    return text\n\ndef elongated_words(text):\n    text = re.sub(r'([A-Z])\\1+', lambda m: m.group(1).upper(), text, flags=re.IGNORECASE)\n    return text\n\ndef lowercasing(text):\n    return text.lower()\n\ndef punctuation(text):\n    return re.sub(r'[^\\w\\s]', ' ', text)\n\ndef sentiment_words(text):\n    texts = word_tokenize(text)\n    len_text = len(texts)\n\n    texts = [t.replace('_', ' ') for t in texts]\n    for i in range(len_text):\n        cp_text = texts[i]\n        if cp_text in not_list: # Xử lý vấn đề phủ định (VD: áo này chẳng đẹp--> áo này notpos)\n            numb_word = 2 if len_text - i - 1 >= 4 else len_text - i - 1\n\n            for j in range(numb_word):\n                if texts[i + j + 1] in pos_list:\n                    texts[i] = 'tệ'\n                    texts[i + j + 1] = ''\n\n                if texts[i + j + 1] in neg_list:\n                    texts[i] = 'tốt'\n                    texts[i + j + 1] = ''\n\n        if cp_text in intensifier_list: # Xử lý vấn đề phủ định (VD: áo này chẳng đẹp--> áo này notpos)\n            numb_word = 2 if len_text - i - 1 >= 4 else len_text - i - 1\n\n            for j in range(numb_word):\n                if texts[i + j + 1] in pos_list:\n                    texts[i] = 'xuất_sắc'\n                    texts[i + j + 1] = ''\n\n                if texts[i + j + 1] in neg_list:\n                    texts[i] = 'thậm_tệ'\n                    texts[i + j + 1] = ''\n                \n        else: #Thêm feature cho những sentiment words (áo này đẹp--> áo này đẹp pos)\n            if cp_text in pos_list:\n                texts.append('tốt')\n            elif cp_text in neg_list:\n                texts.append('tệ')\n\n    text = \" \".join(texts)\n    return text\n\ndef irrelevant_symbol(text):\n    text = text.replace(u'\"', u' ')\n\ndef standardize(text):\n    text = elongated_words(text)\n    text = lowercasing(text)\n    text = emojis_abbreviations(text)\n    text = underthesea.text_normalize(text)\n    text = punctuation(text)\n    text = sentiment_words(text)\n    return text\n\ndef preprocessing(text):\n    text = standardize(text)\n    text = word_tokenize(text, format=\"text\")\n    return text","metadata":{"id":"Yf9VyONbKZeN","execution":{"iopub.status.busy":"2022-12-15T11:03:50.660958Z","iopub.execute_input":"2022-12-15T11:03:50.661654Z","iopub.status.idle":"2022-12-15T11:03:50.714358Z","shell.execute_reply.started":"2022-12-15T11:03:50.661617Z","shell.execute_reply":"2022-12-15T11:03:50.713421Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"for i in range(len(train_text)):\n    train_text[i] = preprocessing(train_text[i])","metadata":{"id":"4N85z6HaWPjC","execution":{"iopub.status.busy":"2022-12-15T11:03:50.715754Z","iopub.execute_input":"2022-12-15T11:03:50.716239Z","iopub.status.idle":"2022-12-15T11:05:22.446448Z","shell.execute_reply.started":"2022-12-15T11:03:50.716204Z","shell.execute_reply":"2022-12-15T11:05:22.445364Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_text","metadata":{"execution":{"iopub.status.busy":"2022-12-15T11:05:22.448215Z","iopub.execute_input":"2022-12-15T11:05:22.448682Z","iopub.status.idle":"2022-12-15T11:05:22.460020Z","shell.execute_reply.started":"2022-12-15T11:05:22.448638Z","shell.execute_reply":"2022-12-15T11:05:22.459006Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"0       xôi dẻo đồ ăn đậm vị hộp xôi được lót lá trông...\n1       gọi giao hàng 1 xuất cari gà bánh nan và 3 miế...\n2       thời_tiết lạnh như này cả nhà rủ nhau đến lega...\n3       em có đọc review thấy mng bảo trà sữa nướng đề...\n4       đồ ăn xuất_sắc nhà_hàng cũng xuất_sắc tất_cả đ...\n                              ...                        \n9479                                           uy_tín tốt\n9480                                        tin_tưởng tốt\n9481                                          lễ_phép tốt\n9482                                              thậm_tệ\n9483                                         xuất_sắc tốt\nLength: 9484, dtype: object"},"metadata":{}}]},{"cell_type":"markdown","source":"# Splitting","metadata":{"id":"51vBcXtiXqRt","_kg_hide-input":false}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_sents, val_sents, train_labels, val_labels = train_test_split(train_text, train_labels, test_size = 0.1)","metadata":{"id":"0YcRbuyWXtJM","execution":{"iopub.status.busy":"2022-12-15T11:05:22.461268Z","iopub.execute_input":"2022-12-15T11:05:22.464082Z","iopub.status.idle":"2022-12-15T11:05:22.472280Z","shell.execute_reply.started":"2022-12-15T11:05:22.464046Z","shell.execute_reply":"2022-12-15T11:05:22.471327Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Byte Pair Encoding","metadata":{"id":"eCJWr26_YYFE"}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.sequence import pad_sequences\n\ntrain_ids = []\nfor sent in train_sents:\n    subwords = '<s> ' + bpe.encode(sent) + ' </s>'\n    encoded_sent = vocab.encode_line(subwords, append_eos=True, add_if_not_exist=False).long().tolist()\n    train_ids.append(encoded_sent)\n\nval_ids = []\nfor sent in val_sents:\n    subwords = '<s> ' + bpe.encode(sent) + ' </s>'\n    encoded_sent = vocab.encode_line(subwords, append_eos=True, add_if_not_exist=False).long().tolist()\n    val_ids.append(encoded_sent)\n    \ntrain_ids = pad_sequences(train_ids, maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"pre\", padding=\"post\")\nval_ids = pad_sequences(val_ids, maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"pre\", padding=\"post\")","metadata":{"id":"SH2JR-LNYhP8","execution":{"iopub.status.busy":"2022-12-15T11:05:22.477394Z","iopub.execute_input":"2022-12-15T11:05:22.477646Z","iopub.status.idle":"2022-12-15T11:05:28.315694Z","shell.execute_reply.started":"2022-12-15T11:05:22.477623Z","shell.execute_reply":"2022-12-15T11:05:28.314672Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# Mask for transformers","metadata":{"id":"jPvOVXigirek"}},{"cell_type":"code","source":"train_masks = []\nfor sent in train_ids:\n    mask = [int(token_id > 0) for token_id in sent]\n    train_masks.append(mask)\n\nval_masks = []\nfor sent in val_ids:\n    mask = [int(token_id > 0) for token_id in sent]\n\n    val_masks.append(mask)","metadata":{"id":"dPOwAsAwiudi","execution":{"iopub.status.busy":"2022-12-15T11:05:28.317450Z","iopub.execute_input":"2022-12-15T11:05:28.317871Z","iopub.status.idle":"2022-12-15T11:05:29.270684Z","shell.execute_reply.started":"2022-12-15T11:05:28.317813Z","shell.execute_reply":"2022-12-15T11:05:29.269420Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# Convert to tensors","metadata":{"id":"VVkLo9sAgcJ1"}},{"cell_type":"code","source":"train_labels = train_labels.astype(int)\nval_labels = val_labels.astype(int)\n\ntrain_labels = np.array(train_labels)\nval_labels = np.array(val_labels)","metadata":{"id":"9MXC6JAK0M0Q","execution":{"iopub.status.busy":"2022-12-15T11:05:29.272370Z","iopub.execute_input":"2022-12-15T11:05:29.272776Z","iopub.status.idle":"2022-12-15T11:05:29.281287Z","shell.execute_reply.started":"2022-12-15T11:05:29.272726Z","shell.execute_reply":"2022-12-15T11:05:29.278771Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\nimport torch\n\ntrain_inputs = torch.tensor(train_ids)\nval_inputs = torch.tensor(val_ids)\ntrain_labels = torch.tensor(train_labels)\nval_labels = torch.tensor(val_labels)\ntrain_masks = torch.tensor(train_masks)\nval_masks = torch.tensor(val_masks)\n\ntrain_data = TensorDataset(train_inputs, train_masks, train_labels)\ntrain_sampler = SequentialSampler(train_data)\ntrain_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=32)\n\nval_data = TensorDataset(val_inputs, val_masks, val_labels)\nval_sampler = SequentialSampler(val_data)\nval_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=32)","metadata":{"id":"6xOeH_94ij9f","execution":{"iopub.status.busy":"2022-12-15T11:05:29.282883Z","iopub.execute_input":"2022-12-15T11:05:29.283187Z","iopub.status.idle":"2022-12-15T11:05:29.432298Z","shell.execute_reply.started":"2022-12-15T11:05:29.283160Z","shell.execute_reply":"2022-12-15T11:05:29.431322Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_sents","metadata":{"execution":{"iopub.status.busy":"2022-12-15T11:05:29.433635Z","iopub.execute_input":"2022-12-15T11:05:29.434112Z","iopub.status.idle":"2022-12-15T11:05:29.443033Z","shell.execute_reply.started":"2022-12-15T11:05:29.434074Z","shell.execute_reply":"2022-12-15T11:05:29.441898Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"1695    vừa đặt thử combo đang giảm còn 25 k cho 1 cơm...\n1590    gì uice n gì oy ở phố lý quốc_sư quán khá dễ t...\n437     quá ng quá ng 1 b hồ văn_quán 1 bữa lẩu không ...\n1272    cuối tuần lên phố đi bộ chơi thì nhất_định phả...\n3399    tuyệt_vời bánh_bèo ngon nhất giống ở quê nhất ...\n                              ...                        \n7101    bún_riêu cá trường_sa ở hà_nội có nhiều cơ_sở ...\n711     fod stret 25 quang_trung hoàn kiếm hà_nội vị_t...\n3037    quán lẩu nướng này thì quá nổi khu mỹ_đình rồi...\n7892    nhân_viên phục_vụ niềm_nở và hỗ_trợ khách_hàng...\n3471    đang đói không biết ăn gì thấy cửa_hàng đang g...\nLength: 8535, dtype: object"},"metadata":{}}]},{"cell_type":"markdown","source":"# Load RobertaForSequenceClassification model","metadata":{"id":"M52wf9vG1tR4"}},{"cell_type":"code","source":"from transformers import RobertaForSequenceClassification, RobertaConfig, AdamW\n\nconfig = RobertaConfig.from_pretrained(\n    \"/kaggle/working/PhoBERT_base_transformers/config.json\", from_tf=False, num_labels = 2, output_hidden_states=False,\n)\nBERT_SA = RobertaForSequenceClassification.from_pretrained(\n    \"/kaggle/working/PhoBERT_base_transformers/model.bin\",\n    config=config\n)\nBERT_SA.cuda()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sl03VgGW10sJ","outputId":"c7cc35d0-1bda-4582-d7af-3a91864f62c9","execution":{"iopub.status.busy":"2022-12-15T11:05:29.444771Z","iopub.execute_input":"2022-12-15T11:05:29.445412Z","iopub.status.idle":"2022-12-15T11:05:36.199992Z","shell.execute_reply.started":"2022-12-15T11:05:29.445376Z","shell.execute_reply":"2022-12-15T11:05:36.198829Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"You are using a model of type bert to instantiate a model of type roberta. This is not supported for all configurations of models and can yield errors.\nSome weights of the model checkpoint at /kaggle/working/PhoBERT_base_transformers/model.bin were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.decoder.bias']\n- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of RobertaForSequenceClassification were not initialized from the model checkpoint at /kaggle/working/PhoBERT_base_transformers/model.bin and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"RobertaForSequenceClassification(\n  (roberta): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(64001, 768, padding_idx=0)\n      (position_embeddings): Embedding(258, 768, padding_idx=0)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (classifier): RobertaClassificationHead(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"# Train model","metadata":{"id":"AzwcRigz6xlX"}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import f1_score, accuracy_score, roc_auc_score\n\ndef flat_accuracy(preds, labels):\n    pred_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    \n    F1_score = f1_score(pred_flat, labels_flat, average='macro')\n    \n    return accuracy_score(pred_flat, labels_flat), F1_score","metadata":{"id":"Y9tWncM78BDG","execution":{"iopub.status.busy":"2022-12-15T11:05:36.201329Z","iopub.execute_input":"2022-12-15T11:05:36.201739Z","iopub.status.idle":"2022-12-15T11:05:36.210081Z","shell.execute_reply.started":"2022-12-15T11:05:36.201701Z","shell.execute_reply":"2022-12-15T11:05:36.209158Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import random\nfrom tqdm import notebook\ndevice = 'cuda'\nepochs = 7\n\nparam_optimizer = list(BERT_SA.named_parameters())\nno_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\noptimizer_grouped_parameters = [\n    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n]\n\noptimizer = AdamW(optimizer_grouped_parameters, lr=1e-5, correct_bias=False)\nmax_auc = 0\n\n\nfor epoch_i in range(0, epochs):\n    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n    print('Training...')\n\n    total_loss = 0\n    BERT_SA.train()\n    train_accuracy = 0\n    nb_train_steps = 0\n    train_f1 = 0\n    preds = []\n    \n    for step, batch in notebook.tqdm(enumerate(train_dataloader)):\n        b_input_ids = batch[0].to(device)\n        b_input_mask = batch[1].to(device)\n        b_labels = batch[2].to(device)\n\n        BERT_SA.zero_grad()\n        outputs = BERT_SA(b_input_ids,\n            token_type_ids=None, \n            attention_mask=b_input_mask, \n            labels=b_labels)\n        loss = outputs[0]\n        total_loss += loss.item()\n        \n        logits = outputs[1].detach().cpu().numpy()\n        label_ids = b_labels.to('cpu').numpy()\n        tmp_train_accuracy, tmp_train_f1 = flat_accuracy(logits, label_ids)\n        train_accuracy += tmp_train_accuracy\n        train_f1 += tmp_train_f1\n        nb_train_steps += 1\n        \n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(BERT_SA.parameters(), 1.0)\n        optimizer.step()\n        \n    avg_train_loss = total_loss / len(train_dataloader)\n    print(\" Accuracy: {0:.4f}\".format(train_accuracy/nb_train_steps))\n    print(\" F1 score: {0:.4f}\".format(train_f1/nb_train_steps))\n    print(\" Average training loss: {0:.4f}\".format(avg_train_loss))\n\n    print(\"Running Validation...\")\n    BERT_SA.eval()\n    eval_loss, eval_accuracy = 0, 0\n    nb_eval_steps, nb_eval_examples = 0, 0\n    eval_f1 = 0\n    for batch in notebook.tqdm(val_dataloader):\n\n        batch = tuple(t.to(device) for t in batch)\n\n        b_input_ids, b_input_mask, b_labels = batch\n\n        with torch.no_grad():\n            outputs = BERT_SA(b_input_ids, \n            token_type_ids=None, \n            attention_mask=b_input_mask)\n            logits = outputs[0]\n            logits = logits.detach().cpu().numpy()\n            for i in range(len(logits)):\n                input = logits[i]\n                predict_train = tensorflow.nn.softmax(input)\n                predict_train = predict_train[1].numpy()\n                preds.append(predict_train)\n            label_ids = b_labels.to('cpu').numpy()\n\n            tmp_eval_accuracy, tmp_eval_f1 = flat_accuracy(logits, label_ids)\n\n            eval_accuracy += tmp_eval_accuracy\n            eval_f1 += tmp_eval_f1\n            nb_eval_steps += 1\n            \n    f1 = eval_f1/nb_eval_steps\n    auc = roc_auc_score(val_labels.numpy(), preds)\n\n    print(\" Accuracy: {0:.4f}\".format(eval_accuracy/nb_eval_steps))\n    print(\" F1 score: {0:.4f}\".format(f1))\n    print(\" ROC-AUC score: {0:.4f}\".format(auc))\n    if auc > max_auc:\n        max_auc = auc\n        BERT_SA.save_pretrained(\"/kaggle/working/bert-sa\")\n        print(epoch_i)\n\nprint(\"Training complete!\")","metadata":{"id":"ZRHyApYq6zyz","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["21515216e2ec4b6096bc64aa41fdab61","817897c7337249578bfec55acc50ad92","fe9ea3a6a6c2493caf98b7a8e19c8775","bd25c781799d490ca43403f562246013","a0f8631776d6446087b916376a651b11","16a1e634ecec40fdbe1ed8a0d3409700","6bb409b7ba0b45aea799df62326df7b5","cfaac0dcf9d04aa4b57c19d7dc3987b1","0af494495e6b4e6593ddf03b06732d45","00b60c8138824ca4977568eee2fd7c2e","8997eb85206c4c289d205a1e4073147d","b9fe907cbdcf4f77a44599ffdefbef83","43e292da3dc446ffb80a795078fcf843","610e0007ca7244c1a8bd02f53d87c189","25dc018a04964291842568abf121f860","35e1be5bc8c44305a768f9a63bd77e69","2337ba553d6149018cbcc57332febe48","b94a21d514b24ea199d2b4feef2c10e5","31225c3dde2049418490f741bf75cdb2","2c44d8f07c274c46936ec3e60aa5aa68","3966621b34ca461badda52e2c2402fba","1d51fd42733d4d858c7a067b949fc2e6","90a745a56b704f14a733c8817581a489","8f074195d96c4bb491fb83a9e382e1ad","de55a9057bee4c26bf19617c60bfe20d","eacf97f304ff4ce2bfae4b3a1c4cae91","f108cfa4904d4dc0a86b8e53d61b1f4d","26187b2656474b4b9564ef3d0100fa64","b2badfde1d7945f69717c6fc868c5307","eedd575554ab421ab7a13eeeedff2c91","fe5de501cec946399a02965ce701dba9","caceb649f2a64bbcac3aaddea6e2d7d8","1d00a96c45c24cfc98a707d970c30574","3a861f7a4936453ba894616ca2b692c9","458dd75f364c4b86a3ec0bf3095543de","0e8bfa0978e244b4af9ad79312d93574","a63856b415024dff90c8fdd34fb17bb3","aad4cc4c8fbb4de3964730273ef2c035","b8c83867902549439a7e1ffd96289f2e","3f96643adc374e0ebaee79ea619e5bfe","b2c1fd8a3ce24cdaa0db8e9548bc26e4","e1410e036b0444ecaeef82162746beb8","c7190de7a95c411d930c4571d679e0df","74369c6949da4a53b81d5d2a4002ad8d","3481c8f496334ffcaa4993ce2be51f36","4de225a3bc6e460fa4dff167c1553eb9","e4764e802630452799633df16ec8d89e","35e2c81994ae4feb8c47f4c925ee2326","a2cd88fd084845deab80936a2b7e1a72","8c36a929b14c4488b004c1323f88dadf","03c177cffbeb4d01838879944e8a47c4","4088a1461a464b98a66952fd8968dd97","13e5435c05ac41db9639a3f50a05322b","5d11b39b33114bcca9b9caf7b20ad0f2","994bc10221ed48b58a631a38f3b45411","c88cf891881c4e04903c61cbadeb24bf","1b2ef6f167f946618098347a5d81d59c","1b1803be329443818921e20e3d047df4","8aa81f9928504513a6448c36345432a7","f444e6f0b4c74bf0ac130052f14db751","074972dcec784abaa8fdeedeb00cb946","e3b3c24b99e34c7ea23d9ddad6213b11","4efdb75f89724227bf08dc18ff11cd56","7e07c6fb8d3b48ffb6ad87915059de0f","b6e1f4769f724ce2955ea01033d41032","e3de6b7210b6488daf0cfb3cba36bf55","521447752fe04897ba631cdc4006c0d2","67c7e585b5de402b88fa17c75ba651df","3eba81130ddc44e9b595fc6f03556b3b","d6f2769cd982457898f8c886dc08afda","2139895107464e8eb31ee8581047d46a","afe4757bdd254a4abea42a7fdd9307fa","3c72ccdce0334bdcbb8f14ffeebcc683","171bb22c6230422e91e6ed01e13a07f2","6cb0516944794aa29ae320c4b4e8e641","35d3057a50664d86a7fb06e309ae75c0","9ff308f29dce490c8f2e17f3b87d594f","c82af7df27a8413bb6afc779f94138a6","3136e18069d842ca81b9b1215dfa80c4","4f2ef901ef8742268a4ac1b0cbf14c21","f55fde6c92ac473f9f5bc56e376bda8a","ee6242db9df043bcacfc553d35581f93","4f84e95eefac465f8ca0e67d919c6bca","b7a8760b66dc4a70883730d9df0dc6be","bc3f177cbec34d60a7b10e38a85b5fcc","f11bd3811de5458ca88c0a176a71707e","84a5fe7d6fe1460e8e4d101774fbfb23","b6f5f587ae0e4191856a4e172676149a","a7dcc5ab48da404aab9a4618aa367ebd","d27fce0e5b544b7fa1aa34a05527304b","68b2ec06780d47618eb448e0ed2cd38a","83eabf101e3e4d81a6c130d7b1d5bbcf","32007ecdff85456e9f5d4e98bd0231b7","d3f8451150394c08b385229a89240469","112d78d72c5b4aaea5052e128d740f3c","01914c2f39f54bada93cd227f13ca0bd","08719c6aaee8419e909b55b9d2f95ce4","fc080d8209be460ea76146a72864c4c7","4e6aaf54b8594fed8e5fae34d9d6da14","337aaca14e45479aac3e36b8da21d1cd","0bb0aa87ffa54f88bc577b7fe2c62461","0f793ec10f5a430c846a77c383d7d7a8","bd698f5211c049439844a02d20980647","1792340ec61e496b9480ffd78fa684e8","3d8a109af782470797f72310cf5f525e","8b992b08d1be4f369858aa7617361f0c","168c146673ac49b1bb516aca8619723c","1be8d961263d4155b2a0efdfa6504ac4","43480c43ea68440ba4be5b67516452f2","d76b60be0c514f6db3f42bb584775732"]},"outputId":"47fe0a93-07cb-49ea-f3ad-0ea36d58a460","execution":{"iopub.status.busy":"2022-12-15T11:05:36.211798Z","iopub.execute_input":"2022-12-15T11:05:36.212212Z","iopub.status.idle":"2022-12-15T11:29:33.458507Z","shell.execute_reply.started":"2022-12-15T11:05:36.212152Z","shell.execute_reply":"2022-12-15T11:29:33.457310Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"======== Epoch 1 / 7 ========\nTraining...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"675ff1b7a87c462db5ee081e7d6ac487"}},"metadata":{}},{"name":"stdout","text":" Accuracy: 0.8802\n F1 score: 0.8011\n Average training loss: 0.2949\nRunning Validation...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9617142d50db44b4a4b219ae701a73db"}},"metadata":{}},{"name":"stderr","text":"2022-12-15 11:08:54.496468: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-15 11:08:54.497410: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-15 11:08:54.497848: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-15 11:08:54.499667: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-12-15 11:08:54.500008: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-15 11:08:54.500485: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-15 11:08:54.500894: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-15 11:08:54.502700: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-15 11:08:54.503197: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-15 11:08:54.503644: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-15 11:08:54.504051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5239 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":" Accuracy: 0.8932\n F1 score: 0.8442\n ROC-AUC score: 0.9355\n0\n======== Epoch 2 / 7 ========\nTraining...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef90fcbbf9024d289693113742e5a7e1"}},"metadata":{}},{"name":"stdout","text":" Accuracy: 0.9356\n F1 score: 0.8996\n Average training loss: 0.1974\nRunning Validation...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3229162c6808486692160cad25a716b8"}},"metadata":{}},{"name":"stdout","text":" Accuracy: 0.9271\n F1 score: 0.8905\n ROC-AUC score: 0.9460\n1\n======== Epoch 3 / 7 ========\nTraining...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2500724ddac64495a98a211b4ac859c4"}},"metadata":{}},{"name":"stdout","text":" Accuracy: 0.9535\n F1 score: 0.9250\n Average training loss: 0.1584\nRunning Validation...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25ceef74148b4b7789b04ce418515677"}},"metadata":{}},{"name":"stdout","text":" Accuracy: 0.9229\n F1 score: 0.8806\n ROC-AUC score: 0.9346\n======== Epoch 4 / 7 ========\nTraining...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b0e9b84fbb541e49798988907ba1a9b"}},"metadata":{}},{"name":"stdout","text":" Accuracy: 0.9618\n F1 score: 0.9382\n Average training loss: 0.1396\nRunning Validation...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45758c3b519d4b9c92569c2eefaca831"}},"metadata":{}},{"name":"stdout","text":" Accuracy: 0.9213\n F1 score: 0.8813\n ROC-AUC score: 0.9268\n======== Epoch 5 / 7 ========\nTraining...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24f763f5b3d441dcbf6d30f6cbcd3086"}},"metadata":{}},{"name":"stdout","text":" Accuracy: 0.9726\n F1 score: 0.9563\n Average training loss: 0.1131\nRunning Validation...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71db3922165c4b5084e6bcfbda924042"}},"metadata":{}},{"name":"stdout","text":" Accuracy: 0.9182\n F1 score: 0.8741\n ROC-AUC score: 0.9182\n======== Epoch 6 / 7 ========\nTraining...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc0df68b305c41828aa1de01f0db6281"}},"metadata":{}},{"name":"stdout","text":" Accuracy: 0.9774\n F1 score: 0.9639\n Average training loss: 0.0977\nRunning Validation...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abc76302aef54ecc8297e4b1674e129d"}},"metadata":{}},{"name":"stdout","text":" Accuracy: 0.9192\n F1 score: 0.8775\n ROC-AUC score: 0.8890\n======== Epoch 7 / 7 ========\nTraining...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"868bb290a1234878a7cea1509bdffd91"}},"metadata":{}},{"name":"stdout","text":" Accuracy: 0.9768\n F1 score: 0.9626\n Average training loss: 0.0922\nRunning Validation...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac64143b537a4fb6bac446de84b3edd3"}},"metadata":{}},{"name":"stdout","text":" Accuracy: 0.9177\n F1 score: 0.8820\n ROC-AUC score: 0.9058\nTraining complete!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Prediction on test set","metadata":{"id":"KlHuTDBdDB7k"}},{"cell_type":"code","source":"df_ts = pd.read_csv(test_path)\n\ntest_text = df_ts['Comment']\ntest_text = test_text.astype(str)\n\nfor i in range(len(test_text)):\n    test_text[i] = preprocessing(test_text[i])\n    \ntest_ids = []\nfor sent in test_text:\n    subwords = '<s> ' + bpe.encode(sent) + ' </s>'\n    encoded_sent = vocab.encode_line(subwords, append_eos=True, add_if_not_exist=False).long().tolist()\n    test_ids.append(encoded_sent)\n\ntest_ids = pad_sequences(test_ids, maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"pre\")\n\ntest_masks = []\nfor sent in test_ids:\n    mask = [int(token_id > 0) for token_id in sent]\n    test_masks.append(mask)","metadata":{"id":"6a91rSP9DMSY","execution":{"iopub.status.busy":"2022-12-15T11:29:33.459836Z","iopub.execute_input":"2022-12-15T11:29:33.460651Z","iopub.status.idle":"2022-12-15T11:30:29.101376Z","shell.execute_reply.started":"2022-12-15T11:29:33.460612Z","shell.execute_reply":"2022-12-15T11:30:29.100081Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"test_inputs = torch.tensor(test_ids)\ntest_masks = torch.tensor(test_masks)\n\ntest_data = TensorDataset(test_inputs, test_masks)\ntest_sampler = SequentialSampler(test_data)\ntest_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=32)","metadata":{"id":"I1sN0UygHWFX","execution":{"iopub.status.busy":"2022-12-15T11:30:29.102705Z","iopub.execute_input":"2022-12-15T11:30:29.103081Z","iopub.status.idle":"2022-12-15T11:30:29.175760Z","shell.execute_reply.started":"2022-12-15T11:30:29.103043Z","shell.execute_reply":"2022-12-15T11:30:29.174902Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"prediction = []\nBERT = RobertaForSequenceClassification.from_pretrained(\"/kaggle/working/bert-sa\").to(device)\nBERT.eval()\nfor batch in notebook.tqdm(test_dataloader):\n    batch = tuple(t.to(device) for t in batch)\n    b_input_ids, b_input_mask = batch\n\n    with torch.no_grad():\n        outputs = BERT(b_input_ids,\n        token_type_ids=None,\n        attention_mask=b_input_mask)\n        logits = outputs[0]\n        logits = logits.detach().cpu().numpy()\n        for i in range(len(logits)):\n            input = logits[i]\n            predict = tensorflow.nn.softmax(input)\n            predict = predict[1].numpy()\n            prediction.append(predict)","metadata":{"id":"ePMsiUSrHhGi","colab":{"base_uri":"https://localhost:8080/","height":101,"referenced_widgets":["855dbb258664480680847c63be4d90fa","9fbeba74103b48249d3b785ffa62e6a7","f864711c16524432a3734cb5d58f2407","5ce0ed74a4e0499a85421bcd7690b38f","401008ba84ea4a4b82833fad15f02822","efab510782724a6196d3a3394207b280","5846ebeed02d4a4999600e49d6897e0d","1abce60585684c568bad4b4909bfd31a","4e2de13aaa824de8869d9e905ed8da12","e8d5383819a14783850e8cd23c59791e","1cc6ef9bcd5c4d49b47978609f13a4f0"]},"outputId":"36eabff1-33bb-44c2-9aa8-9da7d0a7a195","execution":{"iopub.status.busy":"2022-12-15T11:30:29.177162Z","iopub.execute_input":"2022-12-15T11:30:29.177562Z","iopub.status.idle":"2022-12-15T11:31:12.006829Z","shell.execute_reply.started":"2022-12-15T11:30:29.177524Z","shell.execute_reply":"2022-12-15T11:31:12.005847Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/160 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a67c8cf930e241a89cea6d8bc0bc9b5d"}},"metadata":{}}]},{"cell_type":"code","source":"prediction = np.array(prediction)","metadata":{"id":"kS69NI-bMukG","execution":{"iopub.status.busy":"2022-12-15T11:31:12.008514Z","iopub.execute_input":"2022-12-15T11:31:12.009162Z","iopub.status.idle":"2022-12-15T11:31:12.014084Z","shell.execute_reply.started":"2022-12-15T11:31:12.009124Z","shell.execute_reply":"2022-12-15T11:31:12.013146Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"RevId_ts = df_ts['RevId']\nd = {'RevId': RevId_ts, 'Rating': prediction}\nf = pd.DataFrame(d)\nf.to_csv(\"harry.csv\")","metadata":{"id":"OrLKh9YHdO5X","execution":{"iopub.status.busy":"2022-12-15T11:31:12.015653Z","iopub.execute_input":"2022-12-15T11:31:12.016292Z","iopub.status.idle":"2022-12-15T11:31:12.037387Z","shell.execute_reply.started":"2022-12-15T11:31:12.016241Z","shell.execute_reply":"2022-12-15T11:31:12.036589Z"},"trusted":true},"execution_count":26,"outputs":[]}]}